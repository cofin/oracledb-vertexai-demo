"""Database utilities using generic fixture infrastructure."""

from __future__ import annotations

from pathlib import Path
from typing import TYPE_CHECKING

from app.lib.settings import get_settings
from app.utils.fixtures import FixtureExporter, FixtureLoader

if TYPE_CHECKING:
    from sqlspec.driver import AsyncDriverAdapterBase


# Coffee shop table loading order (respects foreign key dependencies)
COFFEE_SHOP_TABLES = [
    "store",
    "product",
    "embedding_cache",
    "response_cache",
    "intent_exemplar",
    "search_metric",
]


async def load_fixtures(tables: list[str] | None = None) -> dict[str, dict | str]:
    """Load fixture data into database using generic loader.

    Args:
        tables: Optional list of specific tables to load

    Returns:
        Dictionary mapping table names to loading results
    """
    from app.server.deps import create_service_provider
    from app.services.base import SQLSpecService

    # Create a temporary service provider to get a driver
    provider = create_service_provider(SQLSpecService)
    service_gen = provider()

    try:
        service = await anext(service_gen)
        settings = get_settings()
        fixtures_dir = Path(settings.db.FIXTURE_PATH)

        loader = FixtureLoader(
            fixtures_dir=fixtures_dir,
            driver=service.driver,
            table_order=COFFEE_SHOP_TABLES,
        )

        results = await loader.load_all_fixtures(specific_tables=tables)

        # Reset sequences for Oracle tables to avoid duplicate key issues
        await _reset_sequences(service.driver)

        return results
    finally:
        await service_gen.aclose()


async def _reset_sequences(driver: AsyncDriverAdapterBase) -> None:
    """Reset Oracle identity sequences to match the current maximum IDs in tables.

    Uses Oracle 23ai's START WITH LIMIT VALUE to automatically resynchronize
    identity sequences after loading fixtures with explicit IDs.
    This prevents duplicate key violations when inserting new records.
    """
    import contextlib

    # Tables with identity columns that need sequence reset
    tables_with_identity = [
        "product",
        "store",
        "response_cache",
        "embedding_cache",
        "intent_exemplar",
        "search_metric",
    ]

    for table in tables_with_identity:
        # Reset identity sequence to max(id) + 1 for each table
        # START WITH LIMIT VALUE inspects the table and sets the sequence to MAX(id) + 1
        with contextlib.suppress(Exception):
            await driver.execute(
                f"ALTER TABLE {table} MODIFY id GENERATED BY DEFAULT ON NULL AS IDENTITY (START WITH LIMIT VALUE)"
            )


async def export_fixtures(
    tables: list[str] | None = None,
    output_dir: Path | None = None,
    compress: bool = True,
) -> dict[str, str]:
    """Export database tables to fixture files.

    Args:
        tables: Optional list of specific tables to export
        output_dir: Output directory (defaults to fixtures dir)
        compress: Whether to gzip compress output

    Returns:
        Dictionary mapping table names to output paths or error messages
    """
    from app.server.deps import create_service_provider
    from app.services.base import SQLSpecService

    # Create a temporary service provider to get a driver
    provider = create_service_provider(SQLSpecService)
    service_gen = provider()

    try:
        service = await anext(service_gen)
        settings = get_settings()
        fixtures_dir = Path(settings.db.FIXTURE_PATH)

        if output_dir is None:
            output_dir = fixtures_dir

        exporter = FixtureExporter(
            fixtures_dir=fixtures_dir,
            driver=service.driver,
            table_order=COFFEE_SHOP_TABLES,
        )

        return await exporter.export_all_fixtures(
            tables=tables,
            output_dir=output_dir,
            compress=compress,
        )
    finally:
        await service_gen.aclose()
